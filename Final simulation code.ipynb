{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0dabd3e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import time\n",
    "import scipy.sparse\n",
    "import nci_linear_setup as ncls\n",
    "import nci_polynomial_setup as ncps\n",
    "\n",
    "import os\n",
    "\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c832c8a",
   "metadata": {},
   "source": [
    "snipe rerun NN 1 layer 3 act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef55f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_module = os.getcwd()  # 当前工作目录\n",
    "\n",
    "#save_path = 'outputFiles/new/'\n",
    "save_path = 'snipe1layer3act/'\n",
    "save_path_graphs = 'snipe1layer3act/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92224465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fos_model_estimator_linear(y, z, A):\n",
    "    \n",
    "    from scipy.optimize import minimize\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "\n",
    "    n = len(z)\n",
    "\n",
    "    # Compute normalized exposure E_i\n",
    "    degrees = A.sum(axis=1)\n",
    "    if scipy.sparse.issparse(degrees):\n",
    "        degrees = np.array(degrees).flatten()\n",
    "    elif isinstance(degrees, np.matrix):\n",
    "        degrees = np.asarray(degrees).flatten()\n",
    "    degrees[degrees == 0] = 1\n",
    "\n",
    "    E = A.dot(z) / degrees\n",
    "\n",
    "    def loss(params):\n",
    "        tau, beta = params\n",
    "        f_E = E * beta\n",
    "        y_hat = tau * z + f_E\n",
    "        return np.sum((y - y_hat)**2)\n",
    "\n",
    "    tau0 = np.mean(y[z == 1]) - np.mean(y[z == 0])\n",
    "    beta0 = 0.1\n",
    "    x0 = [tau0, beta0]\n",
    "\n",
    "    result = minimize(loss, x0, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        tau_hat, beta_hat = result.x\n",
    "        f1 = np.sum(beta_hat)\n",
    "        f0 = 0.0  \n",
    "        return tau_hat + f1 - f0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "\n",
    "def fos_nn_estimator(y, z, A, lr=1e-2, max_iter=1000, h1=4, h2=4, h3=4, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    n = len(z)\n",
    "\n",
    "    # Compute normalized exposure E_i\n",
    "    degrees = A.sum(axis=1)\n",
    "    if scipy.sparse.issparse(degrees):\n",
    "        degrees = np.array(degrees).flatten()\n",
    "    elif isinstance(degrees, np.matrix):\n",
    "        degrees = np.asarray(degrees).flatten()\n",
    "    degrees[degrees == 0] = 1\n",
    "    E = A.dot(z) / degrees  # shape: (n,)\n",
    "\n",
    "    # Convert to torch tensors\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    z = torch.tensor(z, dtype=torch.float32)\n",
    "    E = torch.tensor(E, dtype=torch.float32).view(-1, 1)  # shape (n, 1)\n",
    "\n",
    "    # Define 1-layer neural network with mixed activations\n",
    "    class FoSNet(nn.Module):\n",
    "        def __init__(self, input_dim, h1, h2, h3):\n",
    "            super(FoSNet, self).__init__()\n",
    "            self.linear1 = nn.Linear(input_dim, h1)   # linear only\n",
    "            self.linear2 = nn.Linear(input_dim, h2)   # tanh\n",
    "            self.act2 = nn.Tanh()\n",
    "            self.linear3 = nn.Linear(input_dim, h3)   # PReLU\n",
    "            self.act3 = nn.PReLU()\n",
    "            self.output = nn.Linear(h1 + h2 + h3, 1)\n",
    "\n",
    "        def forward(self, E):\n",
    "            o1 = self.linear1(E)              # linear\n",
    "            o2 = self.act2(self.linear2(E))   # tanh\n",
    "            o3 = self.act3(self.linear3(E))   # PReLU\n",
    "            x = torch.cat([o1, o2, o3], dim=1)  # concat along feature\n",
    "            return self.output(x).squeeze(-1)  # shape: (n,)\n",
    "\n",
    "    class FoSFullModel(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(FoSFullModel, self).__init__()\n",
    "            self.tau = nn.Parameter(torch.tensor(0.0))\n",
    "            self.f_net = FoSNet(input_dim, h1, h2, h3)\n",
    "\n",
    "        def forward(self, z, E):\n",
    "            return self.tau * z + self.f_net(E)\n",
    "\n",
    "    # Initialize and train model\n",
    "    model = FoSFullModel(input_dim=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(z, E)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Compute plug-in ATE\n",
    "    with torch.no_grad():\n",
    "        ones_E = torch.ones_like(E)\n",
    "        f1 = model.f_net(ones_E).mean().item()\n",
    "        f0 = model.f_net(torch.zeros_like(E)).mean().item()\n",
    "        tau_hat = model.tau.item()\n",
    "        ate_hat = tau_hat + f1 - f0\n",
    "\n",
    "    return ate_hat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    from itertools import product\n",
    "    import time\n",
    "\n",
    "    n = 2000\n",
    "    G = 8\n",
    "    T = 250\n",
    "\n",
    "    graphStr = \"er\"\n",
    "\n",
    "    if graphStr == \"sw\":\n",
    "        loadGraphs = True\n",
    "    else:\n",
    "        loadGraphs = False\n",
    "\n",
    "    diag = 10\n",
    "    degrees = [10]\n",
    "    ps = [0.2]\n",
    "    rs = [0.01, 0.1, 0.5, 1, 2, 4]\n",
    "    true_models = ['snipe1', 'snipe2', 'linear', 'logit']\n",
    "\n",
    "    f = open(save_path+'experiments_output.txt', 'w')\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for p, r in product(ps, rs):\n",
    "        for deg in degrees:\n",
    "            for TM in true_models:\n",
    "                print('True Model: {}'.format(TM))\n",
    "                results.extend(run_experiment(G,T,n,p,r,deg,graphStr,TM,diag,loadGraphs))\n",
    "\n",
    "    executionTime = (time.time() - start_time)\n",
    "    print('Runtime in minutes: {}'.format(executionTime/60),file=f)  \n",
    "    print('Runtime in minutes: {}\\n'.format(executionTime/60))       \n",
    "    df = pd.DataFrame.from_records(results)\n",
    "    df.to_csv(save_path+graphStr+'-experiments_output.csv')\n",
    "\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def run_experiment(G,T,n,p,r,degree,graphStr,TM,diag=1, loadGraphs=False):\n",
    "    \n",
    "    offdiag = r*diag   # maximum norm of indirect effect\n",
    "\n",
    "    results = []\n",
    "    dict_base = {'p': p, 'ratio': r, 'n': n, 'TrueM': TM}\n",
    "\n",
    "    sz = str(n) + '-'\n",
    "    for g in range(G):\n",
    "        graph_rep = str(g)\n",
    "        dict_base.update({'Graph':sz+graph_rep})\n",
    "        dict_base.update({'deg': degree})\n",
    "\n",
    "        if loadGraphs:\n",
    "            if graphStr == \"sw\":\n",
    "                A = ncls.loadGraph(save_path_graphs+'SW'+str(n)+'.txt', n*n, True)\n",
    "                n = n*n\n",
    "                dict_base.update({'n':n})\n",
    "                rand_wts = np.random.rand(n,3)\n",
    "            else:\n",
    "                # load weighted graph\n",
    "                name = save_path_graphs + graphStr + sz + graph_rep\n",
    "                A = scipy.sparse.load_npz(name+'-A.npz')\n",
    "                rand_wts = np.load(name+'-wts.npy')\n",
    "        else:\n",
    "            if graphStr == \"CON-prev\":\n",
    "                A = ncls.config_model_nx_prev(n,1000*n)\n",
    "            if graphStr == \"CON\":\n",
    "                A = ncls.config_model_nx(n)\n",
    "            elif graphStr == \"er\":\n",
    "                deg = degree\n",
    "                A = ncls.erdos_renyi(n,deg/n)\n",
    "            elif graphStr == \"sw-ring\":\n",
    "                A = ncls.small_world(n,10,0.1)\n",
    "            elif graphStr == \"SBM\":\n",
    "                clusterSize = int(n/10)\n",
    "                n = 10*clusterSize\n",
    "                prob = 0.02 * np.random.beta(0.5, 0.5, (10, 10)) + np.diagflat(0.08 * np.random.beta(0.5, 0.5, (10, 1)))\n",
    "                A = ncls.SBM(clusterSize, 10*prob/n)\n",
    "            rand_wts = np.random.rand(n,3)\n",
    "\n",
    "    \n",
    "        alpha = rand_wts[:,0].flatten()\n",
    "        C = ncls.simpleWeights(A, diag, offdiag, rand_wts[:,1].flatten(), rand_wts[:,2].flatten())\n",
    "        # TODO: normalize here then absolute bias is fine\n",
    "        \n",
    "        if TM == \"snipe1\":\n",
    "            fy = lambda z: ncls.linear_pom(C, alpha, z)\n",
    "\n",
    "        elif TM == \"snipe2\":\n",
    "            fy = ncps.ppom(2, C, alpha)\n",
    "\n",
    "        elif TM == \"linear\":\n",
    "            deg = np.maximum(np.array(A.sum(axis=1)).flatten(), 1)\n",
    "            fy = lambda z: 1.0 * z + 1.0 * (A.dot(z) / deg)\n",
    "\n",
    "        elif TM == \"logit\":\n",
    "            def f_logit(E): return 1.0 / (1 + np.exp(-1.0 * E))\n",
    "            E = A.dot(np.ones(n)) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1)\n",
    "            fy = lambda z: 1.0 * z + f_logit(A.dot(z) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1))\n",
    "\n",
    "        elif TM == \"exp\":\n",
    "            def f_exp(E): return 1.0 * (1 - np.exp(-1.0 * E))\n",
    "            E = A.dot(np.ones(n)) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1)\n",
    "            fy = lambda z: 1.0 * z + f_exp(A.dot(z) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1))\n",
    "\n",
    "        elif TM == \"ls\":\n",
    "            E = A.dot(np.ones(n)) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1)\n",
    "            fy = lambda z: 1.0 * z + E\n",
    "\n",
    "        elif TM == \"dm\":\n",
    "            fy = lambda z: 1.0 * z\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown true_model: {TM}\")\n",
    "\n",
    "\n",
    "        # compute and print true TTE\n",
    "        TTE = 1/n * np.sum((fy(np.ones(n)) - fy(np.zeros(n))))\n",
    "        dict_base.update({'TTE':TTE})\n",
    "        # print(\"Ground-Truth TTE: {}\".format(TTE))\n",
    "\n",
    "\n",
    "        ####### Estimate ########\n",
    "        estimators = []\n",
    "        \n",
    "        estimators.append(lambda y,z,w: ncls.SNIPE_deg1(len(y), y, w))\n",
    "        estimators.append(lambda y,z,w: ncps.SNIPE_beta(n,y,w))\n",
    "        if TM == \"snipe2\":\n",
    "            estimators.append(lambda y,z,w: ncps.poly_regression_prop(2, y, A, z))\n",
    "            estimators.append(lambda y,z,w: ncps.poly_regression_num(2, y, A, z))\n",
    "        else:\n",
    "            estimators.append(lambda y,z,w: ncls.est_ols_gen(y,A,z))\n",
    "            estimators.append(lambda y,z,w: ncls.est_ols_treated(y,A,z))\n",
    "        \n",
    "        estimators.append(lambda y,z,w: ncls.diff_in_means_naive(y,z))\n",
    "        estimators.append(lambda y,z,w: ncls.diff_in_means_fraction(n,y,A,z,0.75))\n",
    "        estimators.append(lambda y,z,w: fos_model_estimator_linear(y, z, A))\n",
    "        estimators.append(lambda y,z,w: fos_nn_estimator(y, z, A))\n",
    "        alg_names = ['SNIPE1', 'SNIPE2', 'LS-Prop', 'LS-Num', 'DM', 'DM($0.75$)', 'FoS-LINEAR', 'FoS-NN']\n",
    "\n",
    "\n",
    "\n",
    "        N = [np.nonzero(A[[i],:])[1] for i in range(n)]  # neighbors\n",
    "        dep_neighbors = A.dot(A.transpose())\n",
    "        M = [np.nonzero(dep_neighbors[[i],:])[1] for i in range(n)] # dependencies\n",
    "\n",
    "        for i in trange(T, desc=f\"Graph {g} / n={n}\"):\n",
    "            dict_base.update({'rep':i, 'Rand': 'Bernoulli'})\n",
    "            z = ncls.bernoulli(n,p)\n",
    "            y = fy(z)\n",
    "            zz = z/p - (1-z)/(1-p)\n",
    "            w1 = A.dot(zz)            \n",
    "            w2 = ncps.SNIPE_weights(n, p, A, z, 2)\n",
    "\n",
    "            for ind in range(len(estimators)):\n",
    "                if ind == 1:\n",
    "                    est = estimators[ind](y,z,w2)\n",
    "                    dict_base.update({'Estimator': alg_names[ind], \n",
    "                                  'TTE_Estimate': est,\n",
    "                                  'Absolute_Bias': est-TTE,\n",
    "                                  'Bias_squared': (est-TTE)**2,\n",
    "                                  'Relative_Bias': (est-TTE)/TTE})\n",
    "                    results.append(dict_base.copy())\n",
    "                else:\n",
    "                    est = estimators[ind](y,z,w1)\n",
    "                    dict_base.update({'Estimator': alg_names[ind], \n",
    "                                  'TTE_Estimate': est,\n",
    "                                  'Absolute_Bias': est-TTE,\n",
    "                                  'Bias_squared': (est-TTE)**2,\n",
    "                                  'Relative_Bias': (est-TTE)/TTE})\n",
    "                    results.append(dict_base.copy())\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee327d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# 读取数据\n",
    "df = pd.read_csv('snipe1layer3act/er-experiments_output.csv')\n",
    "\n",
    "# 固定 p 和 deg，变化 r\n",
    "ps = [0.2]\n",
    "degrees = [10]  # 你可以修改为你想要的 degree 列表\n",
    "estimators_order = ['SNIPE1', 'SNIPE2', 'LS-Prop', 'LS-Num', 'DM', 'DM($0.75$)', 'FoS-LINEAR', 'FoS-NN']\n",
    "truemodels_order = ['snipe1', 'snipe2', 'linear', 'logit']\n",
    "\n",
    "for p_val in ps:\n",
    "    for deg_val in degrees:\n",
    "        df_filtered = df[(df['p'] == p_val) & (df['deg'] == deg_val)].copy()\n",
    "        if df_filtered.empty:\n",
    "            print(f\"Warning: No data for p={p_val}, deg={deg_val}\")\n",
    "            continue\n",
    "\n",
    "        # 设置分类顺序\n",
    "        df_filtered['Estimator'] = pd.Categorical(df_filtered['Estimator'], categories=estimators_order, ordered=True)\n",
    "        df_filtered['TrueM'] = pd.Categorical(df_filtered['TrueM'], categories=truemodels_order, ordered=True)\n",
    "\n",
    "        # 画图\n",
    "        fig = plt.figure(figsize=(22, 18))\n",
    "        gs = gridspec.GridSpec(len(truemodels_order), len(estimators_order), wspace=0.4, hspace=0.6)\n",
    "\n",
    "        for i, tm in enumerate(truemodels_order):\n",
    "            for j, est in enumerate(estimators_order):\n",
    "                ax = fig.add_subplot(gs[i, j])\n",
    "                data = df_filtered[(df_filtered['TrueM'] == tm) & (df_filtered['Estimator'] == est)]\n",
    "                sns.boxplot(data=data, x='ratio', y='Relative_Bias', ax=ax, color='skyblue', fliersize=1)\n",
    "                ax.axhline(0, color='red', linestyle='--', linewidth=0.8)\n",
    "                ax.set_title(f'{tm} / {est}', fontsize=8)\n",
    "                ax.set_xlabel('')\n",
    "                ax.set_ylabel('')\n",
    "                ax.tick_params(axis='x', labelrotation=45, labelsize=6)\n",
    "                ax.tick_params(axis='y', labelsize=6)\n",
    "                ax.set_ylim(-1, 1)\n",
    "\n",
    "        plt.suptitle(f\"Relative Bias by Ratio (p={p_val}, deg={deg_val})\", fontsize=18)\n",
    "        plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f8cb7a6",
   "metadata": {},
   "source": [
    "ER, NN 1 layer 3 act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d0aeed",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_module = os.getcwd()  # 当前工作目录\n",
    "\n",
    "#save_path = 'outputFiles/new/'\n",
    "save_path = 'ER_NN1lay3act/'\n",
    "save_path_graphs = 'ER_NN1lay3act/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a847c500",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fos_model_estimator_linear(y, z, A):\n",
    "    \n",
    "    from scipy.optimize import minimize\n",
    "    import numpy as np\n",
    "    import scipy\n",
    "\n",
    "    n = len(z)\n",
    "\n",
    "    # Compute normalized exposure E_i\n",
    "    degrees = A.sum(axis=1)\n",
    "    if scipy.sparse.issparse(degrees):\n",
    "        degrees = np.array(degrees).flatten()\n",
    "    elif isinstance(degrees, np.matrix):\n",
    "        degrees = np.asarray(degrees).flatten()\n",
    "    degrees[degrees == 0] = 1\n",
    "\n",
    "    E = A.dot(z) / degrees\n",
    "\n",
    "    def loss(params):\n",
    "        tau, beta = params\n",
    "        f_E = E * beta\n",
    "        y_hat = tau * z + f_E\n",
    "        return np.sum((y - y_hat)**2)\n",
    "\n",
    "    tau0 = np.mean(y[z == 1]) - np.mean(y[z == 0])\n",
    "    beta0 = 0.1\n",
    "    x0 = [tau0, beta0]\n",
    "\n",
    "    result = minimize(loss, x0, method='L-BFGS-B')\n",
    "    if result.success:\n",
    "        tau_hat, beta_hat = result.x\n",
    "        f1 = np.sum(beta_hat)\n",
    "        f0 = 0.0  \n",
    "        return tau_hat + f1 - f0\n",
    "    else:\n",
    "        return np.nan\n",
    "\n",
    "\n",
    "\n",
    "def fos_nn_estimator(y, z, A, lr=1e-2, max_iter=1000, h1=4, h2=4, h3=4, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    n = len(z)\n",
    "\n",
    "    # === Compute normalized exposure E_i ===\n",
    "    degrees = A.sum(axis=1)\n",
    "    if scipy.sparse.issparse(degrees):\n",
    "        degrees = np.array(degrees).flatten()\n",
    "    elif isinstance(degrees, np.matrix):\n",
    "        degrees = np.asarray(degrees).flatten()\n",
    "    degrees[degrees == 0] = 1\n",
    "    E = A.dot(z) / degrees  # shape: (n,)\n",
    "\n",
    "    # === Convert to torch tensors ===\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    z = torch.tensor(z, dtype=torch.float32)\n",
    "    E = torch.tensor(E, dtype=torch.float32).view(-1, 1)  # shape: (n, 1)\n",
    "\n",
    "    # === Define hybrid-activation neural net ===\n",
    "    class FoSNet(nn.Module):\n",
    "        def __init__(self, input_dim, h1, h2, h3):\n",
    "            super(FoSNet, self).__init__()\n",
    "            self.linear1 = nn.Linear(input_dim, h1)   # linear\n",
    "            self.linear2 = nn.Linear(input_dim, h2)   # tanh\n",
    "            self.act2 = nn.Tanh()\n",
    "            self.linear3 = nn.Linear(input_dim, h3)   # PReLU\n",
    "            self.act3 = nn.PReLU()\n",
    "            self.output = nn.Linear(h1 + h2 + h3, 1)\n",
    "\n",
    "        def forward(self, E):\n",
    "            o1 = self.linear1(E)\n",
    "            o2 = self.act2(self.linear2(E))\n",
    "            o3 = self.act3(self.linear3(E))\n",
    "            x = torch.cat([o1, o2, o3], dim=1)\n",
    "            return self.output(x).squeeze(-1)\n",
    "\n",
    "    class FoSFullModel(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(FoSFullModel, self).__init__()\n",
    "            self.tau = nn.Parameter(torch.tensor(0.0))\n",
    "            self.f_net = FoSNet(input_dim, h1, h2, h3)\n",
    "\n",
    "        def forward(self, z, E):\n",
    "            return self.tau * z + self.f_net(E)\n",
    "\n",
    "    # === Fit model ===\n",
    "    model = FoSFullModel(input_dim=1)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(z, E)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # === Plug-in population-level ATE ===\n",
    "    with torch.no_grad():\n",
    "        ones_E = torch.ones_like(E)\n",
    "        f_1 = model.f_net(ones_E).mean().item()\n",
    "        f_0 = model.f_net(torch.zeros_like(E)).mean().item()\n",
    "        tau_hat = model.tau.item()\n",
    "        ate_hat = tau_hat + f_1 - f_0\n",
    "\n",
    "    return ate_hat\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    from itertools import product\n",
    "    import time\n",
    "\n",
    "    n = 4000\n",
    "    G = 10\n",
    "    T = 300\n",
    "\n",
    "    graphStr = \"er\"\n",
    "\n",
    "    if graphStr == \"sw\":\n",
    "        loadGraphs = True\n",
    "    else:\n",
    "        loadGraphs = False\n",
    "\n",
    "    diag = 10\n",
    "    degrees = [10, 50, 100, 200, 500]\n",
    "    ps = [0.5]\n",
    "    rs = [0.5]\n",
    "    true_models = ['snipe1', 'snipe2', 'exp', 'linear','dm']\n",
    "\n",
    "    f = open(save_path+'experiments_output.txt', 'w')\n",
    "    start_time = time.time()\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for p, r in product(ps, rs):\n",
    "        for deg in degrees:\n",
    "            for TM in true_models:\n",
    "                print('True Model: {}'.format(TM))\n",
    "                results.extend(run_experiment(G,T,n,p,r,deg,graphStr,TM,diag,loadGraphs))\n",
    "\n",
    "    executionTime = (time.time() - start_time)\n",
    "    print('Runtime in minutes: {}'.format(executionTime/60),file=f)  \n",
    "    print('Runtime in minutes: {}\\n'.format(executionTime/60))       \n",
    "    df = pd.DataFrame.from_records(results)\n",
    "    df.to_csv(save_path+graphStr+'-experiments_output.csv')\n",
    "\n",
    "\n",
    "from tqdm import trange\n",
    "\n",
    "\n",
    "def run_experiment(G,T,n,p,r,degree,graphStr,TM,diag=1, loadGraphs=False):\n",
    "    \n",
    "    offdiag = r*diag   # maximum norm of indirect effect\n",
    "\n",
    "    results = []\n",
    "    dict_base = {'p': p, 'ratio': r, 'n': n, 'TrueM': TM}\n",
    "\n",
    "    sz = str(n) + '-'\n",
    "    for g in range(G):\n",
    "        graph_rep = str(g)\n",
    "        dict_base.update({'Graph':sz+graph_rep})\n",
    "        dict_base.update({'deg': degree})\n",
    "\n",
    "        if loadGraphs:\n",
    "            if graphStr == \"sw\":\n",
    "                A = ncls.loadGraph(save_path_graphs+'SW'+str(n)+'.txt', n*n, True)\n",
    "                n = n*n\n",
    "                dict_base.update({'n':n})\n",
    "                rand_wts = np.random.rand(n,3)\n",
    "            else:\n",
    "                # load weighted graph\n",
    "                name = save_path_graphs + graphStr + sz + graph_rep\n",
    "                A = scipy.sparse.load_npz(name+'-A.npz')\n",
    "                rand_wts = np.load(name+'-wts.npy')\n",
    "        else:\n",
    "            if graphStr == \"CON-prev\":\n",
    "                A = ncls.config_model_nx_prev(n,1000*n)\n",
    "            if graphStr == \"CON\":\n",
    "                A = ncls.config_model_nx(n)\n",
    "            elif graphStr == \"er\":\n",
    "                deg = degree\n",
    "                A = ncls.erdos_renyi(n,deg/n)\n",
    "            elif graphStr == \"sw-ring\":\n",
    "                A = ncls.small_world(n,10,0.1)\n",
    "            elif graphStr == \"SBM\":\n",
    "                clusterSize = int(n/10)\n",
    "                n = 10*clusterSize\n",
    "                prob = 0.02 * np.random.beta(0.5, 0.5, (10, 10)) + np.diagflat(0.08 * np.random.beta(0.5, 0.5, (10, 1)))\n",
    "                A = ncls.SBM(clusterSize, 10*prob/n)\n",
    "            rand_wts = np.random.rand(n,3)\n",
    "\n",
    "    \n",
    "        alpha = rand_wts[:,0].flatten()\n",
    "        C = ncls.simpleWeights(A, diag, offdiag, rand_wts[:,1].flatten(), rand_wts[:,2].flatten())\n",
    "        # TODO: normalize here then absolute bias is fine\n",
    "        \n",
    "        if TM == \"snipe1\":\n",
    "            fy = lambda z: ncls.linear_pom(C, alpha, z)\n",
    "\n",
    "        elif TM == \"snipe2\":\n",
    "            fy = ncps.ppom(2, C, alpha)\n",
    "\n",
    "        elif TM == \"logit\":\n",
    "            def f_logit(E): return 1.0 / (1 + np.exp(-1.0 * E))\n",
    "            E = A.dot(np.ones(n)) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1)\n",
    "            fy = lambda z: 1.0 * z + f_logit(A.dot(z) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1))\n",
    "\n",
    "        elif TM == \"exp\":\n",
    "            def f_exp(E): return 1.0 * (1 - np.exp(-1.0 * E))\n",
    "            E = A.dot(np.ones(n)) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1)\n",
    "            fy = lambda z: 1.0 * z + f_exp(A.dot(z) / np.maximum(np.array(A.sum(axis=1)).flatten(), 1))\n",
    "\n",
    "        elif TM == \"linear\":\n",
    "            deg = np.maximum(np.array(A.sum(axis=1)).flatten(), 1)\n",
    "            fy = lambda z: 1.0 * z + 1.0 * (A.dot(z) / deg)  # includes self\n",
    "\n",
    "        elif TM == \"ls-prop\":\n",
    "            A_ls = A.copy()\n",
    "            A_ls.setdiag(0)\n",
    "            A_ls.eliminate_zeros()\n",
    "            deg_ls = np.maximum(np.array(A_ls.sum(axis=1)).flatten(), 1)\n",
    "            fy = lambda z: 1.0 * z + 0.5 * (A_ls.dot(z) / deg_ls)  # excludes self, normalized\n",
    "\n",
    "        elif TM == \"ls-num\":\n",
    "            A_ls = A.copy()\n",
    "            A_ls.setdiag(0)\n",
    "            A_ls.eliminate_zeros()\n",
    "            fy = lambda z: 1.0 * z + 0.5 * A_ls.dot(z)  # excludes self, unnormalized\n",
    "\n",
    "\n",
    "        elif TM == \"dm\":\n",
    "            fy = lambda z: 1.0 * z\n",
    "\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown true_model: {TM}\")\n",
    "\n",
    "\n",
    "        # compute and print true TTE\n",
    "        TTE = 1/n * np.sum((fy(np.ones(n)) - fy(np.zeros(n))))\n",
    "        dict_base.update({'TTE':TTE})\n",
    "        # print(\"Ground-Truth TTE: {}\".format(TTE))\n",
    "\n",
    "\n",
    "        ####### Estimate ########\n",
    "        estimators = []\n",
    "        \n",
    "        estimators.append(lambda y,z,w: ncls.SNIPE_deg1(len(y), y, w))\n",
    "        estimators.append(lambda y,z,w: ncps.SNIPE_beta(n,y,w))\n",
    "\n",
    "        if TM == \"snipe2\":\n",
    "            estimators.append(lambda y,z,w: ncps.poly_regression_prop(2, y, A, z))\n",
    "            estimators.append(lambda y,z,w: ncps.poly_regression_num(2, y, A, z))\n",
    "        else:\n",
    "            estimators.append(lambda y,z,w: ncls.est_ols_gen(y,A,z))\n",
    "            estimators.append(lambda y,z,w: ncls.est_ols_treated(y,A,z))\n",
    "        \n",
    "        estimators.append(lambda y,z,w: ncls.diff_in_means_naive(y,z))\n",
    "        estimators.append(lambda y,z,w: ncls.diff_in_means_fraction(n,y,A,z,0.75))\n",
    "\n",
    "        estimators.append(lambda y,z,w: fos_model_estimator_linear(y, z, A))\n",
    "        estimators.append(lambda y,z,w: fos_nn_estimator(y, z, A))\n",
    "        alg_names = ['SNIPE1', 'SNIPE2', 'LS-Prop', 'LS-Num', 'DM', 'DM($0.75$)', 'FoS-LINEAR', 'FoS-NN']\n",
    "\n",
    "\n",
    "\n",
    "        N = [np.nonzero(A[[i],:])[1] for i in range(n)]  # neighbors\n",
    "        dep_neighbors = A.dot(A.transpose())\n",
    "        M = [np.nonzero(dep_neighbors[[i],:])[1] for i in range(n)] # dependencies\n",
    "\n",
    "        for i in trange(T, desc=f\"Graph {g} / n={n}\"):\n",
    "            dict_base.update({'rep':i, 'Rand': 'Bernoulli'})\n",
    "            z = ncls.bernoulli(n,p)\n",
    "            y = fy(z)\n",
    "            zz = z/p - (1-z)/(1-p)\n",
    "            w1 = A.dot(zz)            \n",
    "            w2 = ncps.SNIPE_weights(n, p, A, z, 2)\n",
    "\n",
    "            for ind in range(len(estimators)):\n",
    "                if ind == 1:\n",
    "                    est = estimators[ind](y,z,w2)\n",
    "                    dict_base.update({'Estimator': alg_names[ind], \n",
    "                                  'TTE_Estimate': est,\n",
    "                                  'Absolute_Bias': est-TTE,\n",
    "                                  'Bias_squared': (est-TTE)**2,\n",
    "                                  'Relative_Bias': (est-TTE)/TTE})\n",
    "                    results.append(dict_base.copy())\n",
    "                else:\n",
    "                    est = estimators[ind](y,z,w1)\n",
    "                    dict_base.update({'Estimator': alg_names[ind], \n",
    "                                  'TTE_Estimate': est,\n",
    "                                  'Absolute_Bias': est-TTE,\n",
    "                                  'Bias_squared': (est-TTE)**2,\n",
    "                                  'Relative_Bias': (est-TTE)/TTE})\n",
    "                    results.append(dict_base.copy())\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0082fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# 读取结果数据\n",
    "df = pd.read_csv('ER_NN1lay3act/er-experiments_output.csv')\n",
    "\n",
    "\n",
    "# 创建保存目录\n",
    "os.makedirs('figures_boxplots', exist_ok=True)\n",
    "\n",
    "# Prepare data: filter again just in case and compute relative bias grouped\n",
    "df_filtered = df[(df['p'] == 0.5) & (df['ratio'] == 0.5)].copy()\n",
    "\n",
    "# Ensure proper categorical ordering\n",
    "estimators_order = ['SNIPE1', 'SNIPE2', 'LS-Prop', 'LS-Num', 'DM', 'DM($0.75$)', 'FoS-NN']\n",
    "truemodels_order = ['snipe1', 'snipe2', 'exp', 'linear','dm']\n",
    "df_filtered['Estimator'] = pd.Categorical(df_filtered['Estimator'], categories=estimators_order, ordered=True)\n",
    "df_filtered['TrueM'] = pd.Categorical(df_filtered['TrueM'], categories=truemodels_order, ordered=True)\n",
    "\n",
    "# Set up 6 rows (TrueM) × 8 columns (Estimator)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "fig = plt.figure(figsize=(22, 18))\n",
    "gs = gridspec.GridSpec(len(truemodels_order), len(estimators_order), wspace=0.4, hspace=0.6)\n",
    "\n",
    "for i, tm in enumerate(truemodels_order):\n",
    "    for j, est in enumerate(estimators_order):\n",
    "        ax = fig.add_subplot(gs[i, j])\n",
    "        data = df_filtered[(df_filtered['TrueM'] == tm) & (df_filtered['Estimator'] == est)]\n",
    "        sns.boxplot(data=data, x='deg', y='Relative_Bias', ax=ax, color='skyblue', fliersize=1)\n",
    "        ax.axhline(0, color='red', linestyle='--', linewidth=0.8)\n",
    "        ax.set_title(f'{tm} / {est}', fontsize=8)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "        ax.tick_params(axis='x', labelrotation=45, labelsize=6)\n",
    "        ax.tick_params(axis='y', labelsize=6)\n",
    "        ax.set_ylim(-5, 5)\n",
    "\n",
    "# Global layout\n",
    "plt.suptitle(\"8×6 Grid: Relative Bias by Degree\\n(p=0.5, r=0.5)\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28540a61",
   "metadata": {},
   "source": [
    "multi E, negative effect but positive beta, NN, graph2 ver2 test 1 NN 3 act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b120c461",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_module = os.getcwd()  # 当前工作目录\n",
    "\n",
    "#save_path = 'outputFiles/new/'\n",
    "save_path = 'test1NN3act/'\n",
    "save_path_graphs = 'test1NN3act/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83bedfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import nci_linear_setup as ncls\n",
    "import nci_polynomial_setup as ncps\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# === Parameters ===\n",
    "n = 4000\n",
    "p = 0.3\n",
    "tau, Lambda, alpha = 2.0, -2.0, 1.0\n",
    "k_list = [10, 50, 100, 500, 800]\n",
    "sigma2 = 0.1\n",
    "T = 200 \n",
    "d = 5\n",
    "beta_vec = np.array([-2, 3, -4, 5, -6])\n",
    "\n",
    "# === Functions ===\n",
    "def generate_covariates(n, d):\n",
    "    X = np.random.randn(n, d)\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "\n",
    "def compute_multi_kernel(X, alpha):\n",
    "    d = X.shape[1]\n",
    "    K_list = []\n",
    "    for k in range(d):\n",
    "        x_k = X[:, k][:, np.newaxis]\n",
    "        dist2 = squareform(pdist(x_k)) ** 2\n",
    "        K = np.exp(-alpha * dist2)\n",
    "        np.fill_diagonal(K, 0)\n",
    "        K_list.append(K)\n",
    "    return np.array(K_list)  # shape (d, n, n)\n",
    "\n",
    "def construct_adjacency_from_kernel(K, k):\n",
    "    n = K.shape[0]\n",
    "    A = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        neighbors = np.argsort(-K[i, :])[:k]\n",
    "        A[i, neighbors] = 1\n",
    "    np.fill_diagonal(A, 1)\n",
    "    return scipy.sparse.csr_matrix(A)\n",
    "\n",
    "def generate_treatment(n, p):\n",
    "    return np.random.binomial(1, p, size=n)\n",
    "\n",
    "def compute_vector_exposure(K_list, z):\n",
    "    d, n, _ = K_list.shape\n",
    "    E = np.zeros((n, d))\n",
    "    for k in range(d):\n",
    "        K = K_list[k]\n",
    "        E[:, k] = K @ z / np.maximum(K.sum(axis=1), 1)\n",
    "    return E  # shape (n, d)\n",
    "\n",
    "def generate_outcomes(z, A, K_list, true_model):\n",
    "    E = compute_vector_exposure(K_list, z)\n",
    "    W = A.dot(z / p - (1 - z) / (1 - p))\n",
    "    eps = np.random.normal(0, np.sqrt(sigma2), size=z.shape)\n",
    "    # shared setup\n",
    "    rand_wts = np.random.rand(n, 3)\n",
    "    rand_weight_alpha = rand_wts[:, 0].flatten()\n",
    "    rand_diag = rand_wts[:, 1].flatten()\n",
    "    rand_offdiag = rand_wts[:, 2].flatten()\n",
    "    diag = tau\n",
    "    offdiag = Lambda / (1 + np.exp(-np.sum(beta_vec)))\n",
    "    C = ncls.simpleWeights(A, diag, offdiag, rand_diag, rand_offdiag)\n",
    "\n",
    "    if true_model == 'linear':\n",
    "        f = lambda e: np.dot(beta_vec, e)\n",
    "        f_vec = np.array([f(e) for e in E])\n",
    "        y = tau * z + f_vec + eps\n",
    "        f1 = np.sum(beta_vec)\n",
    "        f0 = 0.0\n",
    "        true_ate = tau + f1 - f0\n",
    "\n",
    "    elif true_model == 'logit':\n",
    "        f = lambda e: Lambda / (1 + np.exp(-np.dot(beta_vec, e)))\n",
    "        f_vec = np.array([f(e) for e in E])\n",
    "        y = tau * z + f_vec + eps\n",
    "        f1 = Lambda / (1 + np.exp(-np.sum(beta_vec)))\n",
    "        f0 = Lambda / (1 + np.exp(0))\n",
    "        true_ate = tau + f1 - f0\n",
    "\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown true_model\")\n",
    "\n",
    "    return y, E, W, true_ate\n",
    "\n",
    "\n",
    "def fos_model_estimator_linear(y, z, K_list):\n",
    "    E = compute_vector_exposure(K_list, z)\n",
    "    d = E.shape[1]\n",
    "\n",
    "    def loss(params):\n",
    "        tau = params[0]\n",
    "        beta = params[1:]\n",
    "        f_E = E @ beta\n",
    "        return np.sum((y - tau * z - f_E) ** 2)\n",
    "\n",
    "    x0 = np.concatenate(([1.0], np.ones(d)))\n",
    "    res = minimize(loss, x0=x0, method='L-BFGS-B')\n",
    "    tau_hat, *beta_hat = res.x\n",
    "\n",
    "    f1 = np.sum(beta_hat)     # when E = [1,...,1]\n",
    "    f0 = 0.0                  # when E = [0,...,0]\n",
    "    return tau_hat + f1 - f0\n",
    "\n",
    "\n",
    "def fos_nn_estimator(y, z, K_list, lr=1e-2, max_iter=1000, h1=4, h2=4, h3=4, seed=0):\n",
    "    \"\"\"\n",
    "    Neural network FoS estimator with one hidden layer, containing:\n",
    "    - h1 units with Linear-only\n",
    "    - h2 units with Tanh\n",
    "    - h3 units with PReLU\n",
    "    Total hidden units = h1 + h2 + h3\n",
    "    \"\"\"\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # === Compute vector exposure E from K_list ===\n",
    "    d, n, _ = K_list.shape\n",
    "    E = np.zeros((n, d))\n",
    "    for k in range(d):\n",
    "        K = K_list[k]\n",
    "        E[:, k] = K @ z / np.maximum(K.sum(axis=1), 1)\n",
    "\n",
    "    # === Convert to torch tensors ===\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    z = torch.tensor(z, dtype=torch.float32)\n",
    "    E = torch.tensor(E, dtype=torch.float32)\n",
    "\n",
    "    # === Define neural network ===\n",
    "    class FoSNet(nn.Module):\n",
    "        def __init__(self, input_dim, h1, h2, h3):\n",
    "            super(FoSNet, self).__init__()\n",
    "            self.linear1 = nn.Linear(input_dim, h1)  # linear only\n",
    "            self.linear2 = nn.Linear(input_dim, h2)  # + tanh\n",
    "            self.act2 = nn.Tanh()\n",
    "            self.linear3 = nn.Linear(input_dim, h3)  # + prelu\n",
    "            self.act3 = nn.PReLU()\n",
    "            self.output = nn.Linear(h1 + h2 + h3, 1)\n",
    "\n",
    "        def forward(self, E):\n",
    "            out1 = self.linear1(E)                      # (n, h1)\n",
    "            out2 = self.act2(self.linear2(E))           # (n, h2)\n",
    "            out3 = self.act3(self.linear3(E))           # (n, h3)\n",
    "            mixed = torch.cat([out1, out2, out3], dim=1)  # (n, h1+h2+h3)\n",
    "            return self.output(mixed).squeeze(-1)         # (n,)\n",
    "\n",
    "    class FoSFullModel(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(FoSFullModel, self).__init__()\n",
    "            self.tau = nn.Parameter(torch.tensor(0.0))\n",
    "            self.f_net = FoSNet(input_dim, h1, h2, h3)\n",
    "\n",
    "        def forward(self, z, E):\n",
    "            return self.tau * z + self.f_net(E)\n",
    "\n",
    "    # === Fit model ===\n",
    "    model = FoSFullModel(input_dim=E.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(z, E)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # === Plug-in ATE\n",
    "    with torch.no_grad():\n",
    "        ones_E = torch.ones_like(E)\n",
    "        f_1 = model.f_net(ones_E).mean().item()\n",
    "        f_0 = model.f_net(torch.zeros_like(E)).mean().item()\n",
    "        tau_hat = model.tau.item()\n",
    "        ate_hat = tau_hat + f_1 - f_0\n",
    "\n",
    "    return ate_hat\n",
    "\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import csgraph\n",
    "\n",
    "from scipy.sparse.linalg import eigsh\n",
    "from scipy.sparse import csgraph\n",
    "\n",
    "def graph_laplacian_covariates_rotated(A, d, m=20, seed=42):\n",
    "    \n",
    "    n = A.shape[0]\n",
    "    L = csgraph.laplacian(A, normed=True)\n",
    "    vals, vecs = eigsh(L, k=m + 1, which='SM')  \n",
    "    spectral_feats = vecs[:, 1:]  \n",
    "\n",
    "    # 随机旋转\n",
    "    rng = np.random.default_rng(seed)\n",
    "    R = rng.normal(size=(m, d))\n",
    "    X_rot = spectral_feats @ R  # shape = (n, d)\n",
    "\n",
    "    # 标准化\n",
    "    X_rot = (X_rot - X_rot.mean(axis=0)) / X_rot.std(axis=0)\n",
    "    return X_rot\n",
    "\n",
    "\n",
    "\n",
    "def generate_symmetric_uniform_graph(n=200, mean_degree=10, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a symmetric undirected graph with degrees sampled from Uniform[0, 2*mean_degree].\n",
    "    Returns:\n",
    "        A (csr_matrix): Symmetric adjacency matrix (with self-loops)\n",
    "        degrees (ndarray): Degree of each node\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    max_deg = 2 * mean_degree\n",
    "    sampled_degrees = np.random.randint(0, max_deg + 1, size=n)\n",
    "    A = np.zeros((n, n), dtype=int)\n",
    "    degree_remain = sampled_degrees.copy()\n",
    "\n",
    "    for i in range(n):\n",
    "        if degree_remain[i] <= 0:\n",
    "            continue\n",
    "        candidates = np.where((degree_remain > 0) & (np.arange(n) != i) & (A[i] == 0))[0]\n",
    "        np.random.shuffle(candidates)\n",
    "        num_to_connect = min(degree_remain[i], len(candidates))\n",
    "        chosen = candidates[:num_to_connect]\n",
    "        for j in chosen:\n",
    "            if degree_remain[i] > 0 and degree_remain[j] > 0:\n",
    "                A[i, j] = 1\n",
    "                A[j, i] = 1\n",
    "                degree_remain[i] -= 1\n",
    "                degree_remain[j] -= 1\n",
    "\n",
    "    np.fill_diagonal(A, 1)\n",
    "    A_sparse = scipy.sparse.csr_matrix(A)\n",
    "    degrees = A_sparse.sum(axis=1).A1\n",
    "    return A_sparse, degrees\n",
    "\n",
    "\n",
    "\n",
    "# === Simulation ===\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "all_records = []\n",
    "\n",
    "for true_model in ['linear', 'logit']:\n",
    "    print(f\"Running true_model = {true_model}\")\n",
    "    for t in range(T):\n",
    "\n",
    "        for k in k_list:\n",
    "            A, degrees = generate_symmetric_uniform_graph(n=n, mean_degree=k)\n",
    "            X = graph_laplacian_covariates_rotated(A, d)\n",
    "            K = compute_multi_kernel(X, alpha)\n",
    "            z = generate_treatment(n, p)\n",
    "            y, E, W, true_ate = generate_outcomes(z, A, K, true_model)\n",
    "\n",
    "            # SNIPE1\n",
    "            w = A.dot(z / p - (1 - z) / (1 - p))\n",
    "            est = ncls.SNIPE_deg1(len(y), y, w)\n",
    "            all_records.append({'rep': t, 'k': k, 'true_model': true_model, 'estimator': 'SNIPE1', 'est': est, 'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate})\n",
    "\n",
    "            # SNIPE2\n",
    "            w2 = ncps.SNIPE_weights(n, p, A, z, 2)\n",
    "            est = ncps.SNIPE_beta(n, y, w2)\n",
    "            all_records.append({'rep': t, 'k': k, 'true_model': true_model, 'estimator': 'SNIPE2', 'est': est, 'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate})\n",
    "\n",
    "            # LS-Num\n",
    "            est = ncls.est_ols_gen(y, A, z)\n",
    "            all_records.append({'rep': t, 'k': k, 'true_model': true_model, 'estimator': 'LS-Num', 'est': est, 'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate})\n",
    "\n",
    "            # LS-Prop\n",
    "            est = ncls.est_ols_treated(y, A, z)\n",
    "            all_records.append({'rep': t, 'k': k, 'true_model': true_model, 'estimator': 'LS-Prop', 'est': est, 'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate})\n",
    "\n",
    "            # DM\n",
    "            est = ncls.diff_in_means_naive(y, z)\n",
    "            all_records.append({'rep': t, 'k': k, 'true_model': true_model, 'estimator': 'DM', 'est': est, 'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate})\n",
    "\n",
    "            # DM(0.75)\n",
    "            est = ncls.diff_in_means_fraction(n, y, A, z, 0.75)\n",
    "            all_records.append({'rep': t, 'k': k, 'true_model': true_model, 'estimator': 'DM(0.75)', 'est': est, 'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate})\n",
    "\n",
    "            # FoS (linear)\n",
    "            est = fos_model_estimator_linear(y, z, K)\n",
    "            all_records.append({'rep': t, 'k': k, 'true_model': true_model, 'estimator': 'FoS (linear)', 'est': est, 'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate})\n",
    "\n",
    "            # FoS (NN)\n",
    "            est = fos_nn_estimator(y, z, K)\n",
    "            all_records.append({'rep': t, 'k': k, 'true_model': true_model, 'estimator': 'FoS (NN)', 'est': est, 'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate})\n",
    "\n",
    "\n",
    "# === Save results ===\n",
    "df = pd.DataFrame(all_records)\n",
    "df.to_csv(os.path.join(save_path, \"simulation_results_all_models.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63797907",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "# === Load simulation result ===\n",
    "df = pd.read_csv(os.path.join(save_path, \"simulation_results_all_models.csv\"))\n",
    "\n",
    "# === Create save folder ===\n",
    "os.makedirs('figures_boxplots2', exist_ok=True)\n",
    "\n",
    "# === Prepare data ===\n",
    "estimators_order = ['SNIPE1', 'SNIPE2', 'LS-Num', 'LS-Prop', 'DM', 'DM(0.75)', 'FoS (NN)']\n",
    "truemodels_order = ['linear', 'logit']\n",
    "    \n",
    "df['estimator'] = pd.Categorical(df['estimator'], categories=estimators_order, ordered=True)\n",
    "df['true_model'] = pd.Categorical(df['true_model'], categories=truemodels_order, ordered=True)\n",
    "\n",
    "# === Plot ===\n",
    "fig = plt.figure(figsize=(24, 18))\n",
    "gs = gridspec.GridSpec(len(truemodels_order), len(estimators_order), wspace=0.4, hspace=0.6)\n",
    "\n",
    "for i, tm in enumerate(truemodels_order):\n",
    "    for j, est in enumerate(estimators_order):\n",
    "        ax = fig.add_subplot(gs[i, j])\n",
    "        subdata = df[(df['true_model'] == tm) & (df['estimator'] == est)]\n",
    "        sns.boxplot(data=subdata, x='k', y='rel_bias', ax=ax, color='skyblue', fliersize=1)\n",
    "        ax.axhline(0, color='red', linestyle='--', linewidth=0.8)\n",
    "        ax.set_title(f'{tm} / {est}', fontsize=8)\n",
    "        ax.set_xlabel('')\n",
    "        ax.set_ylabel('')\n",
    "        ax.tick_params(axis='x', labelrotation=45, labelsize=6)\n",
    "        ax.tick_params(axis='y', labelsize=6)\n",
    "        ax.set_ylim(-5, 5)\n",
    "\n",
    "\n",
    "plt.suptitle(\"8×6 Grid: Relative Bias vs. Degree (k)\\nAll True Models and Estimators\", fontsize=18)\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.96])\n",
    "plt.savefig(\"figures_boxplots/relative_bias_grid.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9635e10",
   "metadata": {},
   "source": [
    "Dose start 0, NN 1 layer 3 act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7a0351",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_module = os.getcwd()  # 当前工作目录\n",
    "\n",
    "#save_path = 'outputFiles/new/'\n",
    "save_path = 'doseS01layer3act/'\n",
    "save_path_graphs = 'doseS01layer3act/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39c46d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import nci_linear_setup as ncls\n",
    "import nci_polynomial_setup as ncps\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# === Parameters ===\n",
    "n = 4000\n",
    "tau, Lambda, alpha = 2.0, -2.0, 1.0\n",
    "k_list = [10]\n",
    "sigma2 = 0.1\n",
    "T = 200 \n",
    "d = 5\n",
    "beta_vec = np.array([1, 2, 2, 1, 3])\n",
    "dose_list = [0.2, 0.4, 0.6, 0.8]\n",
    "\n",
    "# === Functions ===\n",
    "def generate_covariates(n, d):\n",
    "    X = np.random.randn(n, d)\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "def compute_kernel(X, alpha):\n",
    "    dist2 = squareform(pdist(X)) ** 2\n",
    "    K = np.exp(-alpha * dist2)\n",
    "    np.fill_diagonal(K, 0)\n",
    "    return K\n",
    "\n",
    "def compute_multi_kernel(X, alpha):\n",
    "    d = X.shape[1]\n",
    "    K_list = []\n",
    "    for k in range(d):\n",
    "        x_k = X[:, k][:, np.newaxis]\n",
    "        dist2 = squareform(pdist(x_k)) ** 2\n",
    "        K = np.exp(-alpha * dist2)\n",
    "        np.fill_diagonal(K, 0)\n",
    "        K_list.append(K)\n",
    "    return np.array(K_list)  # shape (d, n, n)\n",
    "\n",
    "def construct_adjacency_from_kernel(K, k):\n",
    "    n = K.shape[0]\n",
    "    A = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        neighbors = np.argsort(-K[i, :])[:k]\n",
    "        A[i, neighbors] = 1\n",
    "    np.fill_diagonal(A, 1)\n",
    "    return scipy.sparse.csr_matrix(A)\n",
    "\n",
    "\n",
    "def compute_vector_exposure(K_list, z):\n",
    "    d, n, _ = K_list.shape\n",
    "    E = np.zeros((n, d))\n",
    "    for k in range(d):\n",
    "        K = K_list[k]\n",
    "        E[:, k] = K @ z / np.maximum(K.sum(axis=1), 1)\n",
    "    return E  # shape (n, d)\n",
    "\n",
    "def generate_outcomes(z, A, K_list, true_model, D_fixed):\n",
    "    E = compute_vector_exposure(K_list, z)\n",
    "    eps = np.random.normal(0, np.sqrt(sigma2), size=z.shape)\n",
    "\n",
    "    if true_model == 'linear':\n",
    "        f = lambda e: np.dot(beta_vec, e)\n",
    "        f_vec = np.array([f(e) for e in E])\n",
    "        y = tau * z + f_vec + eps\n",
    "        f0 = 0.0\n",
    "        true_ate = tau * D_fixed + np.mean(f_vec) - f0\n",
    "\n",
    "    elif true_model == 'logit':\n",
    "        f = lambda e: Lambda / (1 + np.exp(-np.dot(beta_vec, e)))\n",
    "        f_vec = np.array([f(e) for e in E])\n",
    "        y = tau * z + f_vec + eps\n",
    "        f0 = Lambda / (1 + np.exp(0))\n",
    "        true_ate = tau * D_fixed + np.mean(f_vec) - f0\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown true_model\")\n",
    "\n",
    "    return y, E, A.dot(z), true_ate\n",
    "\n",
    "\n",
    "\n",
    "def fos_model_estimator_linear(y, z, K_list):\n",
    "    E = compute_vector_exposure(K_list, z)\n",
    "    d = E.shape[1]\n",
    "\n",
    "    def loss(params):\n",
    "        tau = params[0]\n",
    "        beta = params[1:]\n",
    "        f_E = E @ beta\n",
    "        return np.sum((y - tau * z - f_E) ** 2)\n",
    "\n",
    "    x0 = np.concatenate(([1.0], np.ones(d)))\n",
    "    res = minimize(loss, x0=x0, method='L-BFGS-B')\n",
    "    tau_hat, *beta_hat = res.x\n",
    "\n",
    "    D = np.mean(z)\n",
    "    f_E = E @ np.array(beta_hat)\n",
    "    f0 = 0.0  # linear case\n",
    "\n",
    "    ate_dose = tau_hat * D + np.mean(f_E) - f0\n",
    "    return ate_dose\n",
    "\n",
    "\n",
    "\n",
    "def fos_nn_estimator(y, z, K_list, lr=1e-2, max_iter=1000, h1=4, h2=4, h3=4, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # === Compute vector exposure E from K_list ===\n",
    "    d, n, _ = K_list.shape\n",
    "    E = np.zeros((n, d))\n",
    "    for k in range(d):\n",
    "        K = K_list[k]\n",
    "        E[:, k] = K @ z / np.maximum(K.sum(axis=1), 1)\n",
    "\n",
    "    # === Convert to torch tensors ===\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    z = torch.tensor(z, dtype=torch.float32)\n",
    "    E = torch.tensor(E, dtype=torch.float32)\n",
    "\n",
    "    # === Define hybrid-activation neural network ===\n",
    "    class FoSNet(nn.Module):\n",
    "        def __init__(self, input_dim, h1, h2, h3):\n",
    "            super(FoSNet, self).__init__()\n",
    "            self.linear1 = nn.Linear(input_dim, h1)   # linear\n",
    "            self.linear2 = nn.Linear(input_dim, h2)   # tanh\n",
    "            self.act2 = nn.Tanh()\n",
    "            self.linear3 = nn.Linear(input_dim, h3)   # prelu\n",
    "            self.act3 = nn.PReLU()\n",
    "            self.output = nn.Linear(h1 + h2 + h3, 1)\n",
    "\n",
    "        def forward(self, E):\n",
    "            o1 = self.linear1(E)\n",
    "            o2 = self.act2(self.linear2(E))\n",
    "            o3 = self.act3(self.linear3(E))\n",
    "            x = torch.cat([o1, o2, o3], dim=1)\n",
    "            return self.output(x).squeeze(-1)\n",
    "\n",
    "    class FoSFullModel(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(FoSFullModel, self).__init__()\n",
    "            self.tau = nn.Parameter(torch.tensor(0.0))  # scalar τ\n",
    "            self.f_net = FoSNet(input_dim, h1, h2, h3)\n",
    "\n",
    "        def forward(self, z, E):\n",
    "            return self.tau * z + self.f_net(E)\n",
    "\n",
    "    # === Fit model ===\n",
    "    model = FoSFullModel(input_dim=E.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(z, E)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # === Plug-in population-level ATE ===\n",
    "    with torch.no_grad():\n",
    "        D = z.mean().item()\n",
    "        f_E = model.f_net(E).mean().item()\n",
    "        f0 = model.f_net(torch.zeros_like(E)).mean().item()\n",
    "        tau_hat = model.tau.item()\n",
    "        ate_dose = tau_hat * D + f_E - f0\n",
    "\n",
    "    return ate_dose\n",
    "\n",
    "\n",
    "\n",
    "def est_ols_gen_dose(y, A, z):\n",
    "    n = A.shape[0]\n",
    "    X = np.ones((n, 3))\n",
    "    X[:,1] = z\n",
    "    X[:,2] = (A.dot(z) - z) / (np.array(A.sum(axis=1)).flatten() - 1 + 1e-10)\n",
    "    \n",
    "    v = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    D = np.mean(z)\n",
    "    exposure_mean = np.mean(X[:,2])\n",
    "    \n",
    "    return v[1] * D + v[2] * exposure_mean\n",
    "\n",
    "\n",
    "def est_ols_treated_dose(y, A, z):\n",
    "    n = A.shape[0]\n",
    "    X = np.ones((n, 3))\n",
    "    X[:,1] = z\n",
    "    X[:,2] = A.dot(z) - z\n",
    "    \n",
    "    v = np.linalg.lstsq(X, y, rcond=None)[0]\n",
    "    D = np.mean(z)\n",
    "    exposure_mean = np.mean(X[:,2])\n",
    "    \n",
    "    return v[1] * D + v[2] * exposure_mean\n",
    "\n",
    "\n",
    "\n",
    "def generate_fixed_treatment(n, D, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a binary treatment vector with fixed treatment proportion D.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    num_treated = int(D * n)\n",
    "    z = np.zeros(n)\n",
    "    z[:num_treated] = 1\n",
    "    np.random.shuffle(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Simulation ===\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "all_records = []\n",
    "\n",
    "for true_model in ['linear', 'logit']:\n",
    "    print(f\"Running true_model = {true_model}\")\n",
    "    for D_fixed in dose_list:\n",
    "        for t in range(T):\n",
    "            X = generate_covariates(n,d)\n",
    "            K = compute_multi_kernel(X, alpha)\n",
    "            K2 = compute_kernel(X, alpha)\n",
    "            z = generate_fixed_treatment(n, D_fixed)\n",
    "\n",
    "            for k in k_list:\n",
    "                A = construct_adjacency_from_kernel(K2, k)\n",
    "                y, E, W, true_ate = generate_outcomes(z, A, K, true_model, D_fixed)\n",
    "\n",
    "                # LS-Num\n",
    "                est = est_ols_gen_dose(y, A, z)  # 若你采用新版本函数\n",
    "                all_records.append({'rep': t, 'k': k, 'true_model': true_model,\n",
    "                                    'estimator': 'LS-Num', 'est': est, 'true_ate': true_ate,\n",
    "                                    'rel_bias': (est - true_ate) / true_ate,\n",
    "                                    'dose': D_fixed})\n",
    "\n",
    "                # LS-Prop\n",
    "                est = est_ols_treated_dose(y, A, z)\n",
    "                all_records.append({'rep': t, 'k': k, 'true_model': true_model,\n",
    "                                    'estimator': 'LS-Prop', 'est': est, 'true_ate': true_ate,\n",
    "                                    'rel_bias': (est - true_ate) / true_ate,\n",
    "                                    'dose': D_fixed})\n",
    "\n",
    "                # FoS (linear)\n",
    "                est = fos_model_estimator_linear(y, z, K)\n",
    "                all_records.append({\n",
    "                    'rep': t, 'k': k, 'true_model': true_model,\n",
    "                    'estimator': 'FoS (linear)', 'est': est,\n",
    "                    'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate,\n",
    "                    'dose': D_fixed  # 添加 dose\n",
    "                })\n",
    "\n",
    "                # FoS (NN)\n",
    "                est = fos_nn_estimator(y, z, K)\n",
    "                all_records.append({\n",
    "                    'rep': t, 'k': k, 'true_model': true_model,\n",
    "                    'estimator': 'FoS (NN)', 'est': est,\n",
    "                    'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate,\n",
    "                    'dose': D_fixed\n",
    "                })\n",
    "\n",
    "\n",
    "# === Save results ===\n",
    "df = pd.DataFrame(all_records)\n",
    "df.to_csv(os.path.join(save_path, \"simulation_results_all_models.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd689b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# === 读取 simulation 结果 ===\n",
    "df = pd.read_csv(\"doseS01layer3act/simulation_results_all_models.csv\")\n",
    "\n",
    "# === 只保留目标 estimator ===\n",
    "selected_estimators = ['LS-Num', 'LS-Prop', 'FoS (NN)']\n",
    "df_plot = df[df['estimator'].isin(selected_estimators)]\n",
    "\n",
    "# === 设置 Seaborn 风格为浅蓝色配色，与之前风格一致 ===\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\", font_scale=1.0)\n",
    "\n",
    "# === 设置子图结构（2 行 true model × 4 列 estimator） ===\n",
    "true_models = ['linear', 'logit']\n",
    "estimators_order = ['LS-Num', 'LS-Prop', 'FoS (NN)']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 8), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "# === 绘制每个小图 ===\n",
    "for i, model in enumerate(true_models):\n",
    "    for j, est in enumerate(estimators_order):\n",
    "        ax = axes[i, j]\n",
    "        data = df_plot[(df_plot['true_model'] == model) & (df_plot['estimator'] == est)]\n",
    "        sns.boxplot(x='dose', y='rel_bias', data=data, ax=ax, color=\"skyblue\", width=0.6, fliersize=2)\n",
    "\n",
    "        ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(est, fontsize=12)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"True Model: {model}\\nRelative Bias\", fontsize=11)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "        if i == 1:\n",
    "            ax.set_xlabel(\"Dose\", fontsize=11)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "# === 保存图像 ===\n",
    "os.makedirs(\"dose1\", exist_ok=True)\n",
    "plt.savefig(\"dose1/boxplot_rel_bias_by_dose_styled_flipped.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e75722c7",
   "metadata": {},
   "source": [
    "Dose start 0.2, NN 1 layer 3 act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f2c1bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_module = os.getcwd()  # 当前工作目录\n",
    "\n",
    "#save_path = 'outputFiles/new/'\n",
    "save_path = 'doseS021layer3act/'\n",
    "save_path_graphs = 'doseS021layer3act/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a476bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import nci_linear_setup as ncls\n",
    "import nci_polynomial_setup as ncps\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# === Parameters ===\n",
    "n = 4000\n",
    "tau, Lambda, alpha = 2.0, -2.0, 1.0\n",
    "k_list = [10]\n",
    "sigma2 = 0.1\n",
    "T = 200 \n",
    "d = 5\n",
    "beta_vec = np.array([1, 2, 2, 1, 3])\n",
    "dose_list = [0.4, 0.6, 0.8]\n",
    "\n",
    "# === Functions ===\n",
    "def generate_covariates(n, d):\n",
    "    X = np.random.randn(n, d)\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "def compute_kernel(X, alpha):\n",
    "    dist2 = squareform(pdist(X)) ** 2\n",
    "    K = np.exp(-alpha * dist2)\n",
    "    np.fill_diagonal(K, 0)\n",
    "    return K\n",
    "\n",
    "def compute_multi_kernel(X, alpha):\n",
    "    d = X.shape[1]\n",
    "    K_list = []\n",
    "    for k in range(d):\n",
    "        x_k = X[:, k][:, np.newaxis]\n",
    "        dist2 = squareform(pdist(x_k)) ** 2\n",
    "        K = np.exp(-alpha * dist2)\n",
    "        np.fill_diagonal(K, 0)\n",
    "        K_list.append(K)\n",
    "    return np.array(K_list)  # shape (d, n, n)\n",
    "\n",
    "def construct_adjacency_from_kernel(K, k):\n",
    "    n = K.shape[0]\n",
    "    A = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        neighbors = np.argsort(-K[i, :])[:k]\n",
    "        A[i, neighbors] = 1\n",
    "    np.fill_diagonal(A, 1)\n",
    "    return scipy.sparse.csr_matrix(A)\n",
    "\n",
    "\n",
    "def compute_vector_exposure(K_list, z):\n",
    "    d, n, _ = K_list.shape\n",
    "    E = np.zeros((n, d))\n",
    "    for k in range(d):\n",
    "        K = K_list[k]\n",
    "        E[:, k] = K @ z / np.maximum(K.sum(axis=1), 1)\n",
    "    return E  # shape (n, d)\n",
    "\n",
    "def generate_outcomes(z0, z1, A, K_list, true_model, D_fixed):\n",
    "    E0 = compute_vector_exposure(K_list, z0)\n",
    "    E1 = compute_vector_exposure(K_list, z1)\n",
    "    eps = np.random.normal(0, np.sqrt(sigma2), size=n)\n",
    "\n",
    "    if true_model == 'linear':\n",
    "        f = lambda e: np.dot(beta_vec, e)\n",
    "        f_vec0 = np.array([f(e) for e in E0])\n",
    "        f_vec1 = np.array([f(e) for e in E1])\n",
    "        y0 = tau * z0 + f_vec0 + eps\n",
    "        y1 = tau * z1 + f_vec1\n",
    "        true_ate = tau * (D_fixed-0.2) + np.mean(f_vec1) - np.mean(f_vec0)\n",
    "\n",
    "    elif true_model == 'logit':\n",
    "        f = lambda e: Lambda / (1 + np.exp(-np.dot(beta_vec, e)))\n",
    "        f_vec0 = np.array([f(e) for e in E0])\n",
    "        f_vec1 = np.array([f(e) for e in E1])\n",
    "        y0 = tau * z0 + f_vec0 + eps\n",
    "        y1 = tau * z1 + f_vec1\n",
    "        true_ate = tau * (D_fixed-0.2) + np.mean(f_vec1) - np.mean(f_vec0)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown true_model\")\n",
    "\n",
    "    return y0, y1, E0, E1, true_ate\n",
    "\n",
    "\n",
    "\n",
    "def fos_model_estimator_linear(y0, z0, y1, z1, K_list):\n",
    "    E1 = compute_vector_exposure(K_list, z1)\n",
    "    E0 = compute_vector_exposure(K_list, z0)\n",
    "    d = E1.shape[1]\n",
    "    y = np.concatenate([y1, y0])\n",
    "    z = np.concatenate([z1, z0])\n",
    "    E = np.vstack([E1, E0])\n",
    "\n",
    "    def loss(params):\n",
    "        tau = params[0]\n",
    "        beta = params[1:]\n",
    "        f_E = E @ beta\n",
    "        return np.sum((y - tau * z - f_E) ** 2)\n",
    "\n",
    "    x0 = np.concatenate(([1.0], np.ones(d)))\n",
    "    res = minimize(loss, x0=x0, method='L-BFGS-B')\n",
    "    tau_hat, *beta_hat = res.x\n",
    "\n",
    "    D1 = np.mean(z1)\n",
    "    D0 = np.mean(z0)\n",
    "    f_E1 = E1 @ np.array(beta_hat)\n",
    "    f_E0 = E0 @ np.array(beta_hat)\n",
    "\n",
    "    ate_diff = tau_hat * (D1 - D0) + np.mean(f_E1) - np.mean(f_E0)\n",
    "    return ate_diff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fos_nn_estimator(y0, z0, y1, z1, K_list, lr=1e-2, max_iter=1000, h1=4, h2=4, h3=4, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # === 构造 exposure E1 和 E0 ===\n",
    "    E1 = compute_vector_exposure(K_list, z1)\n",
    "    E0 = compute_vector_exposure(K_list, z0)\n",
    "\n",
    "    # === 拼接所有样本 ===\n",
    "    y = np.concatenate([y1, y0])\n",
    "    z = np.concatenate([z1, z0])\n",
    "    E = np.vstack([E1, E0])\n",
    "\n",
    "    # === 转换为 torch tensor ===\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    z = torch.tensor(z, dtype=torch.float32)\n",
    "    E = torch.tensor(E, dtype=torch.float32)\n",
    "\n",
    "    # === 融合激活结构 ===\n",
    "    class FoSNet(nn.Module):\n",
    "        def __init__(self, input_dim, h1, h2, h3):\n",
    "            super(FoSNet, self).__init__()\n",
    "            self.linear1 = nn.Linear(input_dim, h1)   # Linear node\n",
    "            self.linear2 = nn.Linear(input_dim, h2)   # Tanh node\n",
    "            self.act2 = nn.Tanh()\n",
    "            self.linear3 = nn.Linear(input_dim, h3)   # PReLU node\n",
    "            self.act3 = nn.PReLU()\n",
    "            self.output = nn.Linear(h1 + h2 + h3, 1)\n",
    "\n",
    "        def forward(self, E):\n",
    "            o1 = self.linear1(E)\n",
    "            o2 = self.act2(self.linear2(E))\n",
    "            o3 = self.act3(self.linear3(E))\n",
    "            x = torch.cat([o1, o2, o3], dim=1)\n",
    "            return self.output(x).squeeze(-1)\n",
    "\n",
    "    class FoSFullModel(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super(FoSFullModel, self).__init__()\n",
    "            self.tau = nn.Parameter(torch.tensor(0.0))\n",
    "            self.f_net = FoSNet(input_dim, h1, h2, h3)\n",
    "\n",
    "        def forward(self, z, E):\n",
    "            return self.tau * z + self.f_net(E)\n",
    "\n",
    "    # === Fit ===\n",
    "    model = FoSFullModel(input_dim=E.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(z, E)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # === Estimate ATE ===\n",
    "    with torch.no_grad():\n",
    "        E1_torch = torch.tensor(E1, dtype=torch.float32)\n",
    "        E0_torch = torch.tensor(E0, dtype=torch.float32)\n",
    "        D1 = z1.mean()\n",
    "        D0 = z0.mean()\n",
    "        f_E1 = model.f_net(E1_torch).mean().item()\n",
    "        f_E0 = model.f_net(E0_torch).mean().item()\n",
    "        tau_hat = model.tau.item()\n",
    "        ate_diff = tau_hat * (D1 - D0) + f_E1 - f_E0\n",
    "\n",
    "    return ate_diff\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "\n",
    "def est_ols_gen_dose(y1, z1, A, y0, z0, A_baseline=None):\n",
    "    if A_baseline is None:\n",
    "        A_baseline = A\n",
    "\n",
    "    n = len(y1)\n",
    "\n",
    "    # 构造 design matrix for target dose\n",
    "    X1 = np.ones((n, 3))\n",
    "    X1[:, 1] = z1\n",
    "    X1[:, 2] = (A.dot(z1) - z1) / (np.array(A.sum(axis=1)).flatten() - 1 + 1e-10)\n",
    "\n",
    "    v1 = np.linalg.lstsq(X1, y1, rcond=None)[0]\n",
    "    D1 = np.mean(z1)\n",
    "    exposure1 = np.mean(X1[:, 2])\n",
    "\n",
    "    # 构造 design matrix for baseline dose\n",
    "    X0 = np.ones((n, 3))\n",
    "    X0[:, 1] = z0\n",
    "    X0[:, 2] = (A_baseline.dot(z0) - z0) / (np.array(A_baseline.sum(axis=1)).flatten() - 1 + 1e-10)\n",
    "\n",
    "    v0 = np.linalg.lstsq(X0, y0, rcond=None)[0]\n",
    "    D0 = np.mean(z0)\n",
    "    exposure0 = np.mean(X0[:, 2])\n",
    "\n",
    "    return (v1[1] * D1 + v1[2] * exposure1) - (v0[1] * D0 + v0[2] * exposure0)\n",
    "\n",
    "\n",
    "\n",
    "def est_ols_treated_dose(y1, z1, A, y0, z0, A_baseline=None):\n",
    "    if A_baseline is None:\n",
    "        A_baseline = A\n",
    "\n",
    "    n = len(y1)\n",
    "\n",
    "    # 构造 design matrix for target dose\n",
    "    X1 = np.ones((n, 3))\n",
    "    X1[:, 1] = z1\n",
    "    X1[:, 2] = A.dot(z1) - z1\n",
    "\n",
    "    v1 = np.linalg.lstsq(X1, y1, rcond=None)[0]\n",
    "    D1 = np.mean(z1)\n",
    "    exposure1 = np.mean(X1[:, 2])\n",
    "\n",
    "    # 构造 design matrix for baseline dose\n",
    "    X0 = np.ones((n, 3))\n",
    "    X0[:, 1] = z0\n",
    "    X0[:, 2] = A_baseline.dot(z0) - z0\n",
    "\n",
    "    v0 = np.linalg.lstsq(X0, y0, rcond=None)[0]\n",
    "    D0 = np.mean(z0)\n",
    "    exposure0 = np.mean(X0[:, 2])\n",
    "\n",
    "    return (v1[1] * D1 + v1[2] * exposure1) - (v0[1] * D0 + v0[2] * exposure0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_fixed_treatment(n, D, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a binary treatment vector with fixed treatment proportion D.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    num_treated = int(D * n)\n",
    "    z = np.zeros(n)\n",
    "    z[:num_treated] = 1\n",
    "    np.random.shuffle(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Simulation ===\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "all_records = []\n",
    "\n",
    "for true_model in ['linear', 'logit']:\n",
    "    print(f\"Running true_model = {true_model}\")\n",
    "    for D_fixed in dose_list:\n",
    "        for t in range(T):\n",
    "            X = generate_covariates(n,d)\n",
    "            K = compute_multi_kernel(X, alpha)\n",
    "            K2 = compute_kernel(X, alpha)\n",
    "            z1 = generate_fixed_treatment(n, D_fixed)\n",
    "            z0 = generate_fixed_treatment(n, 0.2)\n",
    "\n",
    "            for k in k_list:\n",
    "                A = construct_adjacency_from_kernel(K2, k)\n",
    "                y0, y1, E0, E1, true_ate = generate_outcomes(z0, z1, A, K, true_model, D_fixed)\n",
    "\n",
    "                # LS-Num\n",
    "                est = est_ols_gen_dose(y1, z1, A, y0, z0)  # 若你采用新版本函数\n",
    "                all_records.append({'rep': t, 'k': k, 'true_model': true_model,\n",
    "                                    'estimator': 'LS-Num', 'est': est, 'true_ate': true_ate,\n",
    "                                    'rel_bias': (est - true_ate) / true_ate,\n",
    "                                    'dose': D_fixed})\n",
    "\n",
    "                # LS-Prop\n",
    "                est = est_ols_treated_dose(y1, z1, A, y0, z0)\n",
    "                all_records.append({'rep': t, 'k': k, 'true_model': true_model,\n",
    "                                    'estimator': 'LS-Prop', 'est': est, 'true_ate': true_ate,\n",
    "                                    'rel_bias': (est - true_ate) / true_ate,\n",
    "                                    'dose': D_fixed})\n",
    "\n",
    "                # FoS (linear)\n",
    "                est = fos_model_estimator_linear(y0, z0, y1, z1, K)\n",
    "                all_records.append({\n",
    "                    'rep': t, 'k': k, 'true_model': true_model,\n",
    "                    'estimator': 'FoS (linear)', 'est': est,\n",
    "                    'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate,\n",
    "                    'dose': D_fixed  # 添加 dose\n",
    "                })\n",
    "\n",
    "                # FoS (NN)\n",
    "                est = fos_nn_estimator(y0, z0, y1, z1, K)\n",
    "                all_records.append({\n",
    "                    'rep': t, 'k': k, 'true_model': true_model,\n",
    "                    'estimator': 'FoS (NN)', 'est': est,\n",
    "                    'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate,\n",
    "                    'dose': D_fixed\n",
    "                })\n",
    "\n",
    "\n",
    "# === Save results ===\n",
    "df = pd.DataFrame(all_records)\n",
    "df.to_csv(os.path.join(save_path, \"simulation_results_all_models.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b7d2526",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# === 读取 simulation 结果 ===\n",
    "df = pd.read_csv(\"doseS021layer3act/simulation_results_all_models.csv\")\n",
    "\n",
    "# === 只保留目标 estimator ===\n",
    "selected_estimators = ['LS-Num', 'LS-Prop', 'FoS (NN)']\n",
    "df_plot = df[df['estimator'].isin(selected_estimators)]\n",
    "\n",
    "# === 设置 Seaborn 风格为浅蓝色配色，与之前风格一致 ===\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\", font_scale=1.0)\n",
    "\n",
    "# === 设置子图结构（2 行 true model × 4 列 estimator） ===\n",
    "true_models = ['linear', 'logit']\n",
    "estimators_order = ['LS-Num', 'LS-Prop', 'FoS (NN)']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 8), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "# === 绘制每个小图 ===\n",
    "for i, model in enumerate(true_models):\n",
    "    for j, est in enumerate(estimators_order):\n",
    "        ax = axes[i, j]\n",
    "        data = df_plot[(df_plot['true_model'] == model) & (df_plot['estimator'] == est)]\n",
    "        sns.boxplot(x='dose', y='rel_bias', data=data, ax=ax, color=\"skyblue\", width=0.6, fliersize=2)\n",
    "\n",
    "        ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(est, fontsize=12)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"True Model: {model}\\nRelative Bias\", fontsize=11)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "        if i == 1:\n",
    "            ax.set_xlabel(\"Dose\", fontsize=11)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "# === 保存图像 ===\n",
    "os.makedirs(\"dose1\", exist_ok=True)\n",
    "plt.savefig(\"dose1/boxplot_rel_bias_by_dose_styled_flipped.png\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d383e6f",
   "metadata": {},
   "source": [
    "Dose start 0.4, NN 1 layer 3 act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e0f5d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_module = os.getcwd()  # 当前工作目录\n",
    "\n",
    "#save_path = 'outputFiles/new/'\n",
    "save_path = 'doseS041layer3act/'\n",
    "save_path_graphs = 'doseS041layer3act/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05472039",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse\n",
    "from scipy.optimize import minimize\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import nci_linear_setup as ncls\n",
    "import nci_polynomial_setup as ncps\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# === Parameters ===\n",
    "n = 4000\n",
    "tau, Lambda, alpha = 2.0, -2.0, 1.0\n",
    "k_list = [10]\n",
    "sigma2 = 0.1\n",
    "T = 200 \n",
    "d = 5\n",
    "beta_vec = np.array([1, 2, 2, 1, 3])\n",
    "dose_list = [0.6, 0.8]\n",
    "\n",
    "# === Functions ===\n",
    "def generate_covariates(n, d):\n",
    "    X = np.random.randn(n, d)\n",
    "    return (X - X.mean(axis=0)) / X.std(axis=0)\n",
    "\n",
    "def compute_kernel(X, alpha):\n",
    "    dist2 = squareform(pdist(X)) ** 2\n",
    "    K = np.exp(-alpha * dist2)\n",
    "    np.fill_diagonal(K, 0)\n",
    "    return K\n",
    "\n",
    "def compute_multi_kernel(X, alpha):\n",
    "    d = X.shape[1]\n",
    "    K_list = []\n",
    "    for k in range(d):\n",
    "        x_k = X[:, k][:, np.newaxis]\n",
    "        dist2 = squareform(pdist(x_k)) ** 2\n",
    "        K = np.exp(-alpha * dist2)\n",
    "        np.fill_diagonal(K, 0)\n",
    "        K_list.append(K)\n",
    "    return np.array(K_list)  # shape (d, n, n)\n",
    "\n",
    "def construct_adjacency_from_kernel(K, k):\n",
    "    n = K.shape[0]\n",
    "    A = np.zeros((n, n))\n",
    "    for i in range(n):\n",
    "        neighbors = np.argsort(-K[i, :])[:k]\n",
    "        A[i, neighbors] = 1\n",
    "    np.fill_diagonal(A, 1)\n",
    "    return scipy.sparse.csr_matrix(A)\n",
    "\n",
    "\n",
    "def compute_vector_exposure(K_list, z):\n",
    "    d, n, _ = K_list.shape\n",
    "    E = np.zeros((n, d))\n",
    "    for k in range(d):\n",
    "        K = K_list[k]\n",
    "        E[:, k] = K @ z / np.maximum(K.sum(axis=1), 1)\n",
    "    return E  # shape (n, d)\n",
    "\n",
    "def generate_outcomes(z0, z1, A, K_list, true_model, D_fixed):\n",
    "    E0 = compute_vector_exposure(K_list, z0)\n",
    "    E1 = compute_vector_exposure(K_list, z1)\n",
    "    eps = np.random.normal(0, np.sqrt(sigma2), size=n)\n",
    "\n",
    "    if true_model == 'linear':\n",
    "        f = lambda e: np.dot(beta_vec, e)\n",
    "        f_vec0 = np.array([f(e) for e in E0])\n",
    "        f_vec1 = np.array([f(e) for e in E1])\n",
    "        y0 = tau * z0 + f_vec0 + eps\n",
    "        y1 = tau * z1 + f_vec1\n",
    "        true_ate = tau * (D_fixed-0.4) + np.mean(f_vec1) - np.mean(f_vec0)\n",
    "\n",
    "    elif true_model == 'logit':\n",
    "        f = lambda e: Lambda / (1 + np.exp(-np.dot(beta_vec, e)))\n",
    "        f_vec0 = np.array([f(e) for e in E0])\n",
    "        f_vec1 = np.array([f(e) for e in E1])\n",
    "        y0 = tau * z0 + f_vec0 + eps\n",
    "        y1 = tau * z1 + f_vec1\n",
    "        true_ate = tau * (D_fixed-0.4) + np.mean(f_vec1) - np.mean(f_vec0)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"Unknown true_model\")\n",
    "\n",
    "    return y0, y1, E0, E1, true_ate\n",
    "\n",
    "\n",
    "\n",
    "def fos_model_estimator_linear(y0, z0, y1, z1, K_list):\n",
    "    E1 = compute_vector_exposure(K_list, z1)\n",
    "    E0 = compute_vector_exposure(K_list, z0)\n",
    "    d = E1.shape[1]\n",
    "    y = np.concatenate([y1, y0])\n",
    "    z = np.concatenate([z1, z0])\n",
    "    E = np.vstack([E1, E0])\n",
    "\n",
    "    def loss(params):\n",
    "        tau = params[0]\n",
    "        beta = params[1:]\n",
    "        f_E = E @ beta\n",
    "        return np.sum((y - tau * z - f_E) ** 2)\n",
    "\n",
    "    x0 = np.concatenate(([1.0], np.ones(d)))\n",
    "    res = minimize(loss, x0=x0, method='L-BFGS-B')\n",
    "    tau_hat, *beta_hat = res.x\n",
    "\n",
    "    D1 = np.mean(z1)\n",
    "    D0 = np.mean(z0)\n",
    "    f_E1 = E1 @ np.array(beta_hat)\n",
    "    f_E0 = E0 @ np.array(beta_hat)\n",
    "\n",
    "    ate_diff = tau_hat * (D1 - D0) + np.mean(f_E1) - np.mean(f_E0)\n",
    "    return ate_diff\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def fos_nn_estimator(y0, z0, y1, z1, K_list, lr=1e-2, max_iter=1000, h1=4, h2=4, h3=4, seed=0):\n",
    "    torch.manual_seed(seed)\n",
    "\n",
    "    # === 构造 exposure E1 和 E0 ===\n",
    "    E1 = compute_vector_exposure(K_list, z1)\n",
    "    E0 = compute_vector_exposure(K_list, z0)\n",
    "\n",
    "    # === 拼接所有样本 ===\n",
    "    y = np.concatenate([y1, y0])\n",
    "    z = np.concatenate([z1, z0])\n",
    "    E = np.vstack([E1, E0])\n",
    "\n",
    "    # === 转换为 torch tensor ===\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    z = torch.tensor(z, dtype=torch.float32)\n",
    "    E = torch.tensor(E, dtype=torch.float32)\n",
    "\n",
    "    # === 新的一层网络结构（融合激活）===\n",
    "    class FoSNet(nn.Module):\n",
    "        def __init__(self, input_dim, h1, h2, h3):\n",
    "            super().__init__()\n",
    "            self.linear1 = nn.Linear(input_dim, h1)   # Linear unit\n",
    "            self.linear2 = nn.Linear(input_dim, h2)   # Tanh unit\n",
    "            self.act2 = nn.Tanh()\n",
    "            self.linear3 = nn.Linear(input_dim, h3)   # PReLU unit\n",
    "            self.act3 = nn.PReLU()\n",
    "            self.output = nn.Linear(h1 + h2 + h3, 1)\n",
    "\n",
    "        def forward(self, E):\n",
    "            o1 = self.linear1(E)\n",
    "            o2 = self.act2(self.linear2(E))\n",
    "            o3 = self.act3(self.linear3(E))\n",
    "            x = torch.cat([o1, o2, o3], dim=1)\n",
    "            return self.output(x).squeeze(-1)\n",
    "\n",
    "    class FoSFullModel(nn.Module):\n",
    "        def __init__(self, input_dim):\n",
    "            super().__init__()\n",
    "            self.tau = nn.Parameter(torch.tensor(0.0))\n",
    "            self.f_net = FoSNet(input_dim, h1, h2, h3)\n",
    "\n",
    "        def forward(self, z, E):\n",
    "            return self.tau * z + self.f_net(E)\n",
    "\n",
    "    model = FoSFullModel(input_dim=E.shape[1])\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.MSELoss()\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        optimizer.zero_grad()\n",
    "        y_pred = model(z, E)\n",
    "        loss = loss_fn(y_pred, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        E1_torch = torch.tensor(E1, dtype=torch.float32)\n",
    "        E0_torch = torch.tensor(E0, dtype=torch.float32)\n",
    "        D1 = z1.mean()\n",
    "        D0 = z0.mean()\n",
    "        f_E1 = model.f_net(E1_torch).mean().item()\n",
    "        f_E0 = model.f_net(E0_torch).mean().item()\n",
    "        tau_hat = model.tau.item()\n",
    "        ate_diff = tau_hat * (D1 - D0) + f_E1 - f_E0\n",
    "\n",
    "    return ate_diff\n",
    "\n",
    "\n",
    "\n",
    "def est_ols_gen_dose(y1, z1, A, y0, z0, A_baseline=None):\n",
    "    if A_baseline is None:\n",
    "        A_baseline = A\n",
    "\n",
    "    n = len(y1)\n",
    "\n",
    "    # 构造 design matrix for target dose\n",
    "    X1 = np.ones((n, 3))\n",
    "    X1[:, 1] = z1\n",
    "    X1[:, 2] = (A.dot(z1) - z1) / (np.array(A.sum(axis=1)).flatten() - 1 + 1e-10)\n",
    "\n",
    "    v1 = np.linalg.lstsq(X1, y1, rcond=None)[0]\n",
    "    D1 = np.mean(z1)\n",
    "    exposure1 = np.mean(X1[:, 2])\n",
    "\n",
    "    # 构造 design matrix for baseline dose\n",
    "    X0 = np.ones((n, 3))\n",
    "    X0[:, 1] = z0\n",
    "    X0[:, 2] = (A_baseline.dot(z0) - z0) / (np.array(A_baseline.sum(axis=1)).flatten() - 1 + 1e-10)\n",
    "\n",
    "    v0 = np.linalg.lstsq(X0, y0, rcond=None)[0]\n",
    "    D0 = np.mean(z0)\n",
    "    exposure0 = np.mean(X0[:, 2])\n",
    "\n",
    "    return (v1[1] * D1 + v1[2] * exposure1) - (v0[1] * D0 + v0[2] * exposure0)\n",
    "\n",
    "\n",
    "\n",
    "def est_ols_treated_dose(y1, z1, A, y0, z0, A_baseline=None):\n",
    "    if A_baseline is None:\n",
    "        A_baseline = A\n",
    "\n",
    "    n = len(y1)\n",
    "\n",
    "    # 构造 design matrix for target dose\n",
    "    X1 = np.ones((n, 3))\n",
    "    X1[:, 1] = z1\n",
    "    X1[:, 2] = A.dot(z1) - z1\n",
    "\n",
    "    v1 = np.linalg.lstsq(X1, y1, rcond=None)[0]\n",
    "    D1 = np.mean(z1)\n",
    "    exposure1 = np.mean(X1[:, 2])\n",
    "\n",
    "    # 构造 design matrix for baseline dose\n",
    "    X0 = np.ones((n, 3))\n",
    "    X0[:, 1] = z0\n",
    "    X0[:, 2] = A_baseline.dot(z0) - z0\n",
    "\n",
    "    v0 = np.linalg.lstsq(X0, y0, rcond=None)[0]\n",
    "    D0 = np.mean(z0)\n",
    "    exposure0 = np.mean(X0[:, 2])\n",
    "\n",
    "    return (v1[1] * D1 + v1[2] * exposure1) - (v0[1] * D0 + v0[2] * exposure0)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def generate_fixed_treatment(n, D, seed=None):\n",
    "    \"\"\"\n",
    "    Generate a binary treatment vector with fixed treatment proportion D.\n",
    "    \"\"\"\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    num_treated = int(D * n)\n",
    "    z = np.zeros(n)\n",
    "    z[:num_treated] = 1\n",
    "    np.random.shuffle(z)\n",
    "    return z\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# === Simulation ===\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "all_records = []\n",
    "\n",
    "for true_model in ['linear', 'logit']:\n",
    "    print(f\"Running true_model = {true_model}\")\n",
    "    for D_fixed in dose_list:\n",
    "        for t in range(T):\n",
    "            X = generate_covariates(n,d)\n",
    "            K = compute_multi_kernel(X, alpha)\n",
    "            K2 = compute_kernel(X, alpha)\n",
    "            z1 = generate_fixed_treatment(n, D_fixed)\n",
    "            z0 = generate_fixed_treatment(n, 0.4)\n",
    "\n",
    "            for k in k_list:\n",
    "                A = construct_adjacency_from_kernel(K2, k)\n",
    "                y0, y1, E0, E1, true_ate = generate_outcomes(z0, z1, A, K, true_model, D_fixed)\n",
    "\n",
    "                # LS-Num\n",
    "                est = est_ols_gen_dose(y1, z1, A, y0, z0)  \n",
    "                all_records.append({'rep': t, 'k': k, 'true_model': true_model,\n",
    "                                    'estimator': 'LS-Num', 'est': est, 'true_ate': true_ate,\n",
    "                                    'rel_bias': (est - true_ate) / true_ate,\n",
    "                                    'dose': D_fixed})\n",
    "\n",
    "                # LS-Prop\n",
    "                est = est_ols_treated_dose(y1, z1, A, y0, z0)\n",
    "                all_records.append({'rep': t, 'k': k, 'true_model': true_model,\n",
    "                                    'estimator': 'LS-Prop', 'est': est, 'true_ate': true_ate,\n",
    "                                    'rel_bias': (est - true_ate) / true_ate,\n",
    "                                    'dose': D_fixed})\n",
    "\n",
    "                # FoS (linear)\n",
    "                est = fos_model_estimator_linear(y0, z0, y1, z1, K)\n",
    "                all_records.append({\n",
    "                    'rep': t, 'k': k, 'true_model': true_model,\n",
    "                    'estimator': 'FoS (linear)', 'est': est,\n",
    "                    'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate,\n",
    "                    'dose': D_fixed  # 添加 dose\n",
    "                })\n",
    "\n",
    "                # FoS (NN)\n",
    "                est = fos_nn_estimator(y0, z0, y1, z1, K)\n",
    "                all_records.append({\n",
    "                    'rep': t, 'k': k, 'true_model': true_model,\n",
    "                    'estimator': 'FoS (NN)', 'est': est,\n",
    "                    'true_ate': true_ate, 'rel_bias': (est - true_ate) / true_ate,\n",
    "                    'dose': D_fixed\n",
    "                })\n",
    "\n",
    "\n",
    "# === Save results ===\n",
    "df = pd.DataFrame(all_records)\n",
    "df.to_csv(os.path.join(save_path, \"simulation_results_all_models.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90598b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# === 读取 simulation 结果 ===\n",
    "df = pd.read_csv(\"doseS041layer3act/simulation_results_all_models.csv\")\n",
    "\n",
    "# === 只保留目标 estimator ===\n",
    "selected_estimators = ['LS-Num', 'LS-Prop', 'FoS (NN)']\n",
    "df_plot = df[df['estimator'].isin(selected_estimators)]\n",
    "\n",
    "# === 设置 Seaborn 风格为浅蓝色配色，与之前风格一致 ===\n",
    "sns.set(style=\"whitegrid\", palette=\"pastel\", font_scale=1.0)\n",
    "\n",
    "# === 设置子图结构（2 行 true model × 4 列 estimator） ===\n",
    "true_models = ['linear', 'logit']\n",
    "estimators_order = ['LS-Num', 'LS-Prop', 'FoS (NN)']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, figsize=(18, 8), sharex=True, sharey=True)\n",
    "plt.subplots_adjust(hspace=0.3, wspace=0.2)\n",
    "\n",
    "# === 绘制每个小图 ===\n",
    "for i, model in enumerate(true_models):\n",
    "    for j, est in enumerate(estimators_order):\n",
    "        ax = axes[i, j]\n",
    "        data = df_plot[(df_plot['true_model'] == model) & (df_plot['estimator'] == est)]\n",
    "        sns.boxplot(x='dose', y='rel_bias', data=data, ax=ax, color=\"skyblue\", width=0.6, fliersize=2)\n",
    "\n",
    "        ax.axhline(0, color='red', linestyle='--', linewidth=1)\n",
    "\n",
    "        if i == 0:\n",
    "            ax.set_title(est, fontsize=12)\n",
    "        if j == 0:\n",
    "            ax.set_ylabel(f\"True Model: {model}\\nRelative Bias\", fontsize=11)\n",
    "        else:\n",
    "            ax.set_ylabel(\"\")\n",
    "        if i == 1:\n",
    "            ax.set_xlabel(\"Dose\", fontsize=11)\n",
    "        else:\n",
    "            ax.set_xlabel(\"\")\n",
    "\n",
    "# === 保存图像 ===\n",
    "os.makedirs(\"dose1\", exist_ok=True)\n",
    "plt.savefig(\"dose1/boxplot_rel_bias_by_dose_styled_flipped.png\", dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
